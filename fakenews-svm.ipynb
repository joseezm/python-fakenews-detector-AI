{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUPPORT VECTOR MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = pd.read_excel('test_clean.xlsx')\n",
    "train_clean = pd.read_excel('train_clean.xlsx')\n",
    "train_label = train_clean['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>palo alto calif  years scorning political proc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>videos nodapl native american leaders vow stay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>dont succeed try different sport tim tebow hei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>42 mins ago 1 views 0 comments 0 likes for tim...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>sunday nbcs meet press house minority leader r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  palo alto calif  years scorning political proc...      0\n",
       "1           2  videos nodapl native american leaders vow stay...      0\n",
       "2           3  dont succeed try different sport tim tebow hei...      1\n",
       "3           4  42 mins ago 1 views 0 comments 0 likes for tim...      1\n",
       "4           6  sunday nbcs meet press house minority leader r...      1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 0 0 0 0 1 1 1 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(train_label[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGAR DATOS DE DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Doc2Vec.load(\"d2v-15-30-1.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURACIóN  Y ENTRENAMIENTO DE SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.7432878  -2.6798031   1.1289431  ... -4.82172     0.32812616\n",
      "  -6.011986  ]\n",
      " [ 2.1184945  -1.378394    4.2086143  ... -3.2546227   1.171691\n",
      "  -5.8262672 ]\n",
      " [ 0.97916746  0.18676233  3.9181025  ...  1.5833293   4.224291\n",
      "  -7.937049  ]\n",
      " ...\n",
      " [-1.425989   -0.7634634   2.2431097  ... -3.0998268  -3.3035402\n",
      "   3.2763593 ]\n",
      " [ 1.1221169   6.0870304   3.8994184  ... -3.3284292   3.1974974\n",
      "  -3.5564516 ]\n",
      " [ 0.5340631  -0.45932797  5.699037   ...  3.4976463   0.48058975\n",
      "  -0.26513553]]\n"
     ]
    }
   ],
   "source": [
    "classifier = svm.SVC(kernel = 'rbf', C = 5.0)\n",
    "text_vectors = model.docvecs.vectors_docs\n",
    "classifier.fit(text_vectors, train_label)\n",
    "print(text_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGA Y PROCESAMIENTO DE DATOS DE PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean = pd.read_excel('test_clean.xlsx')\n",
    "\n",
    "test_data = []\n",
    "vector_test_data = []\n",
    "\n",
    "for i in test_clean['text']:\n",
    "    test_data.append(word_tokenize(i))\n",
    "    \n",
    "for i in range(len(test_data)):\n",
    "    vector_test_data.append(model.infer_vector(test_data[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.41031152,  0.97476923,  2.082117  , -0.19333076, -0.07908888,\n",
       "         -2.412675  , -1.3352522 , -1.4661096 , -0.06634827, -1.8654697 ,\n",
       "          0.39162326, -2.4910579 ,  0.50803906,  1.1080458 , -2.305873  ,\n",
       "         -1.2897625 , -1.3019742 ,  2.7420626 ,  1.1688141 ,  0.36126283,\n",
       "         -1.3059695 , -0.8540542 , -0.5429103 ,  1.1870023 ,  0.81169486,\n",
       "         -2.12311   , -2.0382042 , -0.975055  , -0.8150144 , -1.4603306 ]],\n",
       "       dtype=float32),\n",
       " array([[ 0.85446954,  0.59597373,  0.9809887 ,  0.71076745,  0.24104466,\n",
       "          2.447914  , -0.76497656,  0.6817385 ,  0.70553774,  0.77901244,\n",
       "          0.38908646, -0.47983614, -0.21267116, -1.8483146 ,  1.1892155 ,\n",
       "         -1.0174977 ,  1.8730855 ,  1.8026403 ,  1.6823827 ,  1.9649135 ,\n",
       "          0.08581686, -1.5826792 ,  1.0871506 , -0.08734801, -1.3282615 ,\n",
       "         -0.73604023, -2.3805892 ,  0.9051435 , -1.454741  , -0.25260597]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(vector_test_data)):\n",
    "    vector_test_data[i] = np.array(vector_test_data[i]).reshape(1,30)\n",
    "    \n",
    "vector_test_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASIFICANDO DATOS DE PRUEBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "test_results = []\n",
    "for i in vector_test_data:\n",
    "#     print(classifier.predict(i))\n",
    "    test_results.append(classifier.predict(i)[0])\n",
    "    \n",
    "# predict = classifier.predict(vector_test_data[1])\n",
    "# print(predict)\n",
    "print(test_results[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALCULANDO PRESICIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.751100352112676\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_results, test_clean['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
