{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPLEMENTACIÓN DE DOC2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('train_clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>house dem aide didnt comeys letter jason chaff...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>feeling life circles roundabout heads straight...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>truth fired october 29 2016 tension intelligen...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>videos 15 civilians killed single airstrike id...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>print iranian woman sentenced years prison ira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  house dem aide didnt comeys letter jason chaff...      1\n",
       "1           1  feeling life circles roundabout heads straight...      0\n",
       "2           2  truth fired october 29 2016 tension intelligen...      1\n",
       "3           3  videos 15 civilians killed single airstrike id...      1\n",
       "4           4  print iranian woman sentenced years prison ira...      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCION DE ETIQUETADO DE DOCUMENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagged_document(list_of_list_of_words):\n",
    "   for i, list_of_words in enumerate(list_of_list_of_words):\n",
    "      yield TaggedDocument(list_of_words, [i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOKENIZANDO TEXTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18211\n"
     ]
    }
   ],
   "source": [
    "tokenize_text = []\n",
    "\n",
    "for i in data['text']:\n",
    "    tokenize_text.append(word_tokenize(i))\n",
    "    \n",
    "print(len(tokenize_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['house', 'dem', 'aide', 'didnt', 'comeys', 'letter', 'jason', 'chaffetz', 'tweeted', 'darrell', 'lucus', 'october', '30', '2016', 'subscribe', 'jason', 'chaffetz', 'stump', 'american', 'fork', 'utah', 'image', 'courtesy', 'michael', 'jolley', 'available', 'creative', 'commonsby', 'license', 'apologies', 'keith', 'olbermann', 'doubt', 'worst', 'person', 'world', 'weekfbi', 'director', 'james', 'comey', 'according', 'house', 'democratic', 'aide', 'looks', 'like', 'know', 'secondworst', 'person', 'well', 'turns', 'comey', 'sent', 'nowinfamous', 'letter', 'announcing', 'fbi', 'looking', 'emails', 'related', 'hillary', 'clintons', 'email', 'server', 'ranking', 'democrats', 'relevant', 'committees', 'didnt', 'hear', 'comey', 'tweet', 'republican', 'committee', 'chairmen', 'know', 'comey', 'notified', 'republican', 'chairmen', 'democratic', 'ranking', 'members', 'house', 'intelligence', 'judiciary', 'oversight', 'committees', 'agency', 'reviewing', 'emails', 'recently', 'discovered', 'order', 'contained', 'classified', 'information', 'long', 'letter', 'went', 'out', 'oversight', 'committee', 'chairman', 'jason', 'chaffetz', 'set', 'political', 'world', 'ablaze', 'tweet', 'fbi', 'dir', 'informed', 'me', 'the', 'fbi', 'learned', 'existence', 'emails', 'appear', 'pertinent', 'investigation', 'case', 'reopened', 'jason', 'chaffetz', 'jasoninthehouse', 'october', '28', '2016', 'course', 'know', 'case', 'comey', 'actually', 'saying', 'reviewing', 'emails', 'light', 'an', 'unrelated', 'casewhich', 'know', 'anthony', 'weiners', 'sexting', 'teenager', 'apparently', 'little', 'things', 'facts', 'didnt', 'matter', 'chaffetz', 'utah', 'republican', 'vowed', 'initiate', 'raft', 'investigations', 'hillary', 'winsat', 'years', 'worth', 'possibly', 'entire', 'terms', 'worth', 'them', 'apparently', 'chaffetz', 'thought', 'fbi', 'work', 'himresulting', 'tweet', 'briefly', 'roiled', 'nation', 'cooler', 'heads', 'realized', 'dud', 'according', 'senior', 'house', 'democratic', 'aide', 'misreading', 'letter', 'chaffetz', 'sins', 'aide', 'told', 'shareblue', 'boss', 'democrats', 'didnt', 'know', 'comeys', 'letter', 'timeand', 'checked', 'twitter', 'democratic', 'ranking', 'members', 'relevant', 'committees', 'didnt', 'receive', 'comeys', 'letter', 'republican', 'chairmen', 'fact', 'democratic', 'ranking', 'members', 'didn', 'receive', 'chairman', 'oversight', 'government', 'reform', 'committee', 'jason', 'chaffetz', 'tweeted', 'public', 'lets', 'weve', 'got', 'right', 'fbi', 'director', 'tells', 'chaffetz', 'gop', 'committee', 'chairmen', 'major', 'development', 'potentially', 'politically', 'explosive', 'investigation', 'chaffetz', 'colleagues', 'courtesy', 'let', 'democratic', 'counterparts', 'know', 'it', 'instead', 'according', 'aide', 'twitter', 'talk', 'daily', 'kos', 'comey', 'provided', 'advance', 'notice', 'letter', 'chaffetz', 'republicans', 'giving', 'time', 'turn', 'spin', 'machine', 'good', 'theater', 'far', 'suggests', 'case', 'all', 'far', 'suggests', 'comey', 'grossly', 'incompetent', 'tonedeaf', 'suggest', 'however', 'chaffetz', 'acting', 'way', 'makes', 'dan', 'burton', 'darrell', 'issa', 'look', 'like', 'models', 'responsibility', 'bipartisanship', 'didnt', 'decency', 'notify', 'ranking', 'member', 'elijah', 'cummings', 'explosive', 'doesnt', 'trample', 'basic', 'standards', 'fairness', 'dont', 'know', 'does', 'granted', 'its', 'likely', 'chaffetz', 'answer', 'this', 'sits', 'ridiculously', 'republican', 'district', 'anchored', 'provo', 'orem', 'cook', 'partisan', 'voting', 'index', 'r25', 'gave', 'mitt', 'romney', 'punishing', '78', 'percent', 'vote', '2012', 'moreover', 'republican', 'house', 'leadership', 'given', 'support', 'chaffetz', 'planned', 'fishing', 'expedition', 'doesnt', 'mean', 'cant', 'turn', 'hot', 'lights', 'him', 'all', 'textbook', 'example', 'house', 'republican', 'control', 'second', 'worst', 'person', 'world', 'darrell', 'lucus', 'darrell', '30something', 'graduate', 'university', 'north', 'carolina', 'considers', 'journalist', 'old', 'school', 'attempt', 'turn', 'member', 'religious', 'right', 'college', 'succeeded', 'turning', 'religious', 'rights', 'worst', 'nightmarea', 'charismatic', 'christian', 'unapologetic', 'liberal', 'desire', 'stand', 'scared', 'silence', 'increased', 'survived', 'abusive', 'threeyear', 'marriage', 'know', 'daily', 'kos', 'christian', 'dem', 'nc', 'follow', 'twitter', 'darrelllucus', 'connect', 'facebook', 'click', 'buy', 'darrell', 'mello', 'yello', 'connect']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETIQUETANDO DOCUMENTOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_training = list(tagged_document(tokenize_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['feeling', 'life', 'circles', 'roundabout', 'heads', 'straight', 'line', 'intended', 'destination', 'hillary', 'clinton', 'remains', 'big', 'woman', 'campus', 'leafy', 'liberal', 'wellesley', 'massachusetts', 'votes', 'likely', 'inauguration', 'dress', 'remainder', 'days', 'way', 'miss', 'havisham', 'forever', 'wore', 'wedding', 'dress', 'speaking', 'great', 'expectations', 'hillary', 'rodham', 'overflowed', '48', 'years', 'ago', 'addressed', 'wellesley', 'graduating', 'class', 'president', 'college', 'informed', 'gathered', '1969', 'students', 'needed', 'no', 'debate', 'far', 'ascertain', 'spokesman', 'be', 'kind', 'like', 'democratic', 'primaries', '2016', 'minus', 'terms', 'unknown', 'seven', 'sisters', 'school', 'i', 'glad', 'miss', 'adams', 'clear', 'speaking', 'today', '400', 'us', 'miss', 'rodham', 'told', 'classmates', 'appointing', 'edger', 'bergen', 'charlie', 'mccarthys', 'mortimer', 'snerds', 'attendance', 'bespectacled', 'granny', 'glasses', 'awarding', 'matronly', 'wisdom', 'john', 'lennon', 'wisdom', 'took', 'issue', 'previous', 'speaker', 'despite', 'win', 'election', 'seat', 'u', 's', 'senate', 'reconstruction', 'edward', 'brooke', 'came', 'criticism', 'calling', 'empathy', 'goals', 'protestors', 'criticized', 'tactics', 'clinton', 'senior', 'thesis', 'saul', 'alinsky', 'lamented', 'black', 'power', 'demagogues', 'elitist', 'arrogance', 'repressive', 'intolerance', 'new', 'left', 'similar', 'words', 'coming', 'republican', 'necessitated', 'brief', 'rebuttal', 'trust', 'rodham', 'ironically', 'observed', '1969', 'this', 'word', 'asked', 'class', 'rehearsal', 'wanted', 'them', 'came', 'said', 'talk', 'trust', 'talk', 'lack', 'trust', 'way', 'feel', 'others', 'talk', 'trust', 'bust', 'it', 'feeling', 'permeates', 'generation', 'understood', 'distrusted', 'trust', 'bust', 'certainly', 'busted', 'clintons', '2016', 'plans', 'certainly', 'understand', 'people', 'distrusted', 'her', 'whitewater', 'travelgate', 'vast', 'conspiracy', 'benghazi', 'missing', 'emails', 'clinton', 'distrusted', 'voice', 'friday', 'load', 'compromising', 'road', 'broadening', 'political', 'horizons', 'distrust', 'american', 'people', 'trump', 'edged', '48', 'percent', '38', 'percent', 'question', 'immediately', 'prior', 'novembers', 'election', 'stood', 'major', 'reason', 'closing', 'horizons', 'clinton', 'described', 'vanquisher', 'supporters', 'embracing', 'lie', 'con', 'alternative', 'facts', 'a', 'assault', 'truth', 'reason', 'failed', 'explain', 'american', 'people', 'chose', 'lies', 'truth', 'as', 'history', 'majors', 'today', 'know', 'well', 'people', 'power', 'invent', 'facts', 'attack', 'question', 'them', 'mark', 'beginning', 'end', 'free', 'society', 'offered', 'that', 'hyperbole', 'like', 'people', 'emerge', '1960s', 'hillary', 'clinton', 'embarked', 'long', 'strange', 'trip', 'high', 'school', 'goldwater', 'girl', 'wellesley', 'college', 'republican', 'president', 'democratic', 'politician', 'clinton', 'drank', 'times', 'place', 'gave', 'degree', 'significantly', 'went', 'idealist', 'cynic', 'comparison', 'wellesley', 'commencement', 'addresses', 'show', 'way', 'when', 'lamented', 'for', 'long', 'leaders', 'viewed', 'politics', 'art', 'possible', 'challenge', 'practice', 'politics', 'art', 'making', 'appears', 'impossible', 'possible', 'now', 'big', 'woman', 'campus', 'odd', 'woman', 'white', 'house', 'wonders', 'current', 'station', 'possible', 'why', 'arent', '50', 'points', 'ahead', 'asked', 'september', 'asks', 'isnt', 'president', 'woman', 'famously', 'dubbed', 'congenital', 'liar', 'safire', 'concludes', 'lies', 'theirs', 'mind', 'you', 'hers', 'getting', 'stood', 'election', 'day', 'like', 'finding', 'jilted', 'bride', 'wedding', 'day', 'inspires', 'dangerous', 'delusions'], tags=[1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_training[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURACIÓN DE MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 50\n",
    "vec_size = 30\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARGAR DATOS AL MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(data_for_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMENZAR ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model.train(data_for_training,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.epochs)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "model.save(\"d2v-taged.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
